{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab5/blob/main/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.png\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Image Convolution\n",
    "\n",
    "Ove laboratorijske vježbe se rješavaju u Google Colabu i spremaju na GitHub repozitorij koji je povezan na GitHub Classroom.\n",
    "\n",
    "## Kako riješiti zadatke?\n",
    "\n",
    "1. Prihvatite zadatak putem Google Classroom linka koji ćete dobiti. Google Classroom će kreirati repozitorij na vašem računu.\n",
    "2. Uđite u novokreiran repozitorij na vašem računu i kliknite na **.ipynb** datoteku, zatim kliknite **Open in Colab**.\n",
    "3. Zadatke rješavate u Google Colabu.\n",
    "\n",
    "## Kako spremiti (predati) zadatke?\n",
    "\n",
    "1. Unutar **Google Colaba** kliknite na **Open settings** kotačić u gornjem desnom kutu.\n",
    "2. Kliknite na **GitHub** tab i odaberite kvačicu za **Access private repositories and organizations**.\n",
    "3. Otvorit će se novi prozor da dodate pristup GitHubu. Kod **ferit-osirv** kliknite **Grant**.  \n",
    "4. Spremite i izađite iz postavki.\n",
    "\n",
    "\n",
    "5. Kliknite na **File > Save a copy in GitHub**.\n",
    "6. Odaberite kreiran repozitorij labosa **koji uključuje vaše ime**.\n",
    "\n",
    "> *Napomena:* Korake 1-4 morate napraviti samo prvi put."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kopiranje datoteka iz GitHub repozitorija\n",
    "\n",
    "Za izradu vježbi bit će vam potrebne slike i druge datoteke koje će se nalaziti u GitHub repozitoriju vježbe. Ovakva komanda će biti dostupna u notebooku svake vježbe. Ona će kopirati datoteke s GitHuba u Google Colab okruženje.\n",
    "\n",
    "**Ovu komandu je potrebno pokrenuti prije nego što krenete raditi svaku vježbu.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf clone && git clone https://github.com/ferit-osirv/lab5 clone && cp -a clone/. ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![](images/conv.png)\n",
    "\n",
    "Generally, convolution is a mathematical operation between two functions. In the context of this assignment, however, we will focus on discrete 2D convolution between two square images, as that is most relevant for image processing. Convolution is denoted as $I(A) \\star k(B)$ where $I(A)$ is an image $I(A) \\in \\mathbb{R}^{W \\times H}$ and $k(B)$ is a matrix $k(B) \\in \\mathbb{R}^{a \\times b}$ indexed by locations $B \\in \\mathbb{N}^2$ called the **convolutional kernel**. At pixel $(x, y)$, the convolution operation is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "(I \\star k)(x, y) = \\sum_{i=-a}^{a} \\sum_{j=-b}^{b} I[x + i, y + j] k[i, j]\n",
    "\\end{equation}\n",
    " \n",
    "Explained differently, the resulting image is produced by sliding the kernel over the input image pixel by pixel. At each pixel location, values where the kernel and the image overlap are multiplied, and all of the products are summed together to form the corresponding pixel's value in the output image.\n",
    "\n",
    "![](images/no_padding_no_strides.gif)\n",
    "\n",
    "While mathematically a simple operation, convolution is exceedingly powerful and can produce almost endless transformations of an image. It's most commonly used for filtering --- a convolution can elegantly find patterns in the image and increase their intensity. One such example is the convolution with a kernel called the Prewitt operator:\n",
    "\n",
    "\\begin{equation}\n",
    "I_y(A) = I(A) \\star \\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "When convolved with this kernel, the resulting image has high-intensity pixels in regions where vertical edges are present, and low intensity everywhere else. This can be seen in the following image:\n",
    "\n",
    "![](images/prewitt-example.png)\n",
    "\n",
    "Vertical edges necessarily have to have a large jump in values going from left to right or right to left. Otherwise, there would be no perceptible edge. This kernel takes advantage of that fact to accentuate parts of the image where there is such a jump. It does this by replacing each pixel with the difference between the pixels on its left and its right.\n",
    "\n",
    "This process happens as follows. For each pixel of the input image, the kernel is placed such that it is centered on that pixel. This means that the values of the pixel as well as its neighbors above and below are all multiplied by zero. The neighbors on the left are multiplied by -1, and the ones on the right are multiplied by 1. Summed together, the result represents the sum of the values on the right of the pixel, minus the sum of the values on the left.\n",
    "\n",
    "To illustrate this, let us consider $1 \\times 3$ region of the image where no vertical edges are present:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "128 & 130 & 136\\\\\n",
    "\\end{bmatrix}\n",
    "\\star\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sum_{i,j}\n",
    "\\begin{bmatrix}\n",
    "-1 \\times 0 + 0 \\times 128 + 1 \\times 130\\\\ \n",
    "-1 \\times 128 + 0 \\times 130 + 1 \\times 136\\\\\n",
    "-1 \\times 130 + 0 \\times 136 + 1 \\times 0\\\\\n",
    "\\end{bmatrix}\n",
    "= 8\n",
    "\\end{equation}\n",
    "\n",
    "This section of the image does not contain a vertical edge, so the convolution result is a relatively low value. In a standard image with values in $[0, 255)$, 8 would appear almost completely black.\n",
    "\n",
    "However, consider some section of the image where a vertical edge is indeed present:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "63 & 66 & 132\\\\\n",
    "\\end{bmatrix}\n",
    "\\star\n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "-1 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\sum_{i,j}\n",
    "\\begin{bmatrix}\n",
    "-1 \\times 0 + 0 \\times 64 + 1 \\times 66\\\\ \n",
    "-1 \\times 64 + 0 \\times 66 + 1 \\times 132\\\\\n",
    "-1 \\times 66 + 0 \\times 132 + 1 \\times 0\\\\\n",
    "\\end{bmatrix}\n",
    "= 68\n",
    "\\end{equation}\n",
    "\n",
    "The value is now much larger due to the difference between the left and right sides of the image. This example demonstrates how a relatively simple kernel can capture complex features of an image.\n",
    "\n",
    "Beyond edge detection, there are many commonly used convolution kernels to perform tasks such as blurring, sharpening, or denoising images. A convolutional neural network can leverage the power of the convolution by stringing together sequences of intricate kernels to match complex patterns in the image.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "- https://vincmazet.github.io/bip/filtering/convolution.html\n",
    "- https://arxiv.org/pdf/1603.07285.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first implement a convolution operation from scratch. Convert the following equation into code:\n",
    "\n",
    "\\begin{equation}\n",
    "(I \\star k)(x, y) = \\sum_{i=1}^{a} \\sum_{j=1}^{b} I[x + i, y + j] k[i, j].\n",
    "\\end{equation}\n",
    "\n",
    "This equation defines the convolution value for a single pixel $(x, y)$, where $I$ is the image and $k$ is a kernel of size $a \\times b$. You will need to perform this operation for each pixel. Complete `convolve_py` by returning a convolved image.\n",
    "\n",
    "**Finish the code blocks below at the TODO comments. You do not need to change the rest of the code, or code blocks that do not have TODO comments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_py(img, kernel):\n",
    "  '''\n",
    "  Convolves an image with a kernel.\n",
    "  Uses pure Python (no Numpy).\n",
    "\n",
    "  Args:\n",
    "    img: 2D numpy array of the image (grayscale, e.g. (128,128))\n",
    "    kernel: 2D numpy array of the kernel\n",
    "  '''\n",
    "  # Get the dimensions of the image and kernel\n",
    "  img_height, img_width = img.shape\n",
    "  kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "  conv_result = np.zeros(img.shape)\n",
    "  img = np.pad(img, (1, 1), 'constant', constant_values=(0, 0))\n",
    "\n",
    "  for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "      # TODO: compute pixel (x, y) using equation above\n",
    "      # Note: If the kernel goes outside the boundary of the image, assume that the values outside the image are zero.\n",
    "      # Note: In mathematical notation, matrix indices start at 1. In Python, matrix indices start at 0.\n",
    "      # Note: The `img` pixel (x, y) is `img[y, x]`.\n",
    "\n",
    "  return conv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('images/cells.jpg', cv.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "kernel = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "\n",
    "img_out = convolve_py(img, kernel)\n",
    "print(img_out.min(), img_out.max())\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up convolution with numpy\n",
    "\n",
    "This time, implement the equation above using Numpy functions on matrices to calculate the convolved pixel value as `np.sum(window * kernel)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_np(img, kernel):\n",
    "  '''\n",
    "  Convolves an image with a kernel.\n",
    "  Uses Numpy.\n",
    "\n",
    "  Args:\n",
    "    img: 2D numpy array of the image (grayscale)\n",
    "    kernel: 2D numpy array of the kernel\n",
    "  '''\n",
    "  # Get the dimensions of the image and kernel\n",
    "  img_height, img_width = img.shape\n",
    "  kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "  conv_result = np.zeros(img.shape)\n",
    "  img = np.pad(img, ((1, 1), (1, 1)), 'constant', constant_values=0)\n",
    "\n",
    "  for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "      # TODO\n",
    "\n",
    "  return conv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/cells.jpg', cv.IMREAD_GRAYSCALE)\n",
    "img_out = convolve_np(img, kernel)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check which implementation is faster using the timeit library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Time the pure Python version\n",
    "time_py = timeit.timeit('convolve_py(img, kernel)', number=5, globals=globals())\n",
    "print('Pure Python: {:.5f}s'.format(time_py))\n",
    "\n",
    "# Time the dot product version (should be a few seconds faster)\n",
    "time_np = timeit.timeit('convolve_np(img, kernel)', number=5, globals=globals())\n",
    "print('NumPy: {:.5f}s'.format(time_dot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding kernels\n",
    "\n",
    "Different convolutional kernels can achieve different effects such as:\n",
    "\n",
    " - edge detection\n",
    " - image engancement (e.g. sharpening)\n",
    " - blurring\n",
    " - denoising\n",
    " - feature detection\n",
    "\n",
    "You can see various examples of kernels here:\n",
    "\n",
    " - https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    " - https://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find a good convolutional kernel to perform edge detection on the cell image.\n",
    "\n",
    "kernel_edge = # TODO\n",
    "img_out = cv.filter2D(img, -1, kernel_edge)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find a kernel to blur the image and show the blurred image.\n",
    "# Then, run the edge detection kernel on the blurred image and show the result.\n",
    "\n",
    "kernel_blur = # TODO\n",
    "# TODO: blur + edge detection, show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using large kernels\n",
    "\n",
    "The next code block constructs an image. You job is to recreate the image using a convolution.\n",
    "\n",
    "Hint: https://vincmazet.github.io/bip/filtering/convolution.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = np.zeros((100, 100))\n",
    "circle_origins = [(50, 50), (20, 20), (80, 20)]\n",
    "circle_radius = 10\n",
    "\n",
    "for (x, y) in circle_origins:\n",
    "  img_out = cv.circle(img_out, (x, y), circle_radius, 1, -1)\n",
    "\n",
    "plt.imshow(img_out, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.zeros((circle_radius * 2 + 1, circle_radius * 2 + 1))\n",
    "kernel = cv.circle(kernel, (circle_radius, circle_radius), circle_radius, 1, -1)\n",
    "plt.imshow(kernel, cmap='gray')\n",
    "\n",
    "img = np.zeros((100, 100))\n",
    "\n",
    "# TODO: Modify `img` such that a convolution img * kernel produces the same result as `img_out`.\n",
    "\n",
    "\n",
    "# OpenCV's built-in convolution function:\n",
    "img = cv.filter2D(img, -1, kernel)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Convolutions for Feature Detection\n",
    "\n",
    "Assume we want to detect the eyes on the following image:\n",
    "\n",
    "![](images/woman_darkhair.png)\n",
    "\n",
    "Notice that the eyes consist of a light region and then a dark region (iris). We may be able to detect the eyes using the following kernel:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & -1 & -1\\\\\n",
    "1 & 1 & -1 & -1\\\\\n",
    "1 & 1 & -1 & -1\\\\\n",
    "1 & 1 & -1 & -1\\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "This kernel will take the difference between the left two pixels and the right two pixels. If the pixels on the left are high and on the right are low, the resulting value will be high.\n",
    "\n",
    "Implement a convolution with this kernel in the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/woman_darkhair.png', cv.IMREAD_GRAYSCALE)\n",
    "img = cv.resize(img, (0, 0), fx=0.5, fy=0.5)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "kernel = # TODO: Write the kernel from above as a numpy matrix\n",
    "\n",
    "img_out = cv.filter2D(img, -1, kernel)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also find the mouth. Guided by the patterns you see in the pixel intensities, try to construct a kernel which will highlight the mouth in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/woman_darkhair.tif', cv.IMREAD_GRAYSCALE)\n",
    "cv.imwrite('images/woman_darkhair.png', img)\n",
    "\n",
    "kernel = # TODO: Write a kernel to find the mouth\n",
    "\n",
    "img_out = cv.filter2D(img, -1, kernel)\n",
    "plt.imshow(img_out, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Don't forget to save the notebook on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
